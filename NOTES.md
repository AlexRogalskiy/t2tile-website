## Content for main page

The T2 Tile project is an attempt to build the world's first indefinitely scalable computational stack. An entirely new hardware and software architecture, which is no longer incumbered by the limits of CPU and RAM. It sacrifices the ideals of hardware and software determinism, allowing for robustness, over efficiency, to emerge as a key driving concept for the ability to grow indefinitely. It's a radical idea, that requires suspension of the core computational foundations we've come to rely on, but on the other hand, it's a satisfying answer to the question, "Is this how computers have to be? Is this the only way there is?"

## #2

Traditional CPU and RAM computing –– the Von Neumann Architecture –– has been at the foundational base of computer science for the last 7 decades. But in recent years, Moore's Law has slowed, or as some have argued, died all-together, and the security concerns, and more importantly, realized consequences of them on top of this deterministic architecture, has us asking if there might be another way.

The T2 Tile project suspends the idea that we are bound to an architecture based on the hardware and software determinism that lets our computations focus solely on being correct and efficient; 100% reproducable, 100% of the time. Instead, much like the physical world around us, it looks at robustness as a first-class concept, and on top of that builds a distributed, spatial computational stack that, without needing to be deterministic, can scale indefinitely, from here to the horizon.

## #3

The T2 Tile project suspends the idea that we are bound to an architecture based on correct and efficient deterministic hardware and software. Instead, much like the physical world and living systems around us, it employs robustness as a first-class concept, and on top of that, builds a distributed, spatial computational stack that scales indefinitely, from here to the horizon.

## #4

The T2 Tile project is an attempt to build the world's first indefinitely scalable computational stack. First, we suspend the idea that we must be bound to an architecture based on correct and efficient deterministic hardware and software. Instead, much like the physical world around us, we look to robustness as a foundational requirement, building living systems as vessels for digital computation that is firstly robust, then as correct as possible, and finally, as efficient as necessary.